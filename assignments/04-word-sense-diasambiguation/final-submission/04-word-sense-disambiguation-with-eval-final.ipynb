{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation using Neural Networks\n",
    "Adam Ek\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with static distributional vectors is the difficulty of distinguishing between different *word senses*. We will continue our exploration of word vectors by considering *trainable vectors* or *word embeddings* for Word Sense Disambiguation (WSD).\n",
    "\n",
    "The goal of word sense disambiguation is to train a model to find the sense of a word (homonyms of a word-form). For example, the word \"bank\" can mean \"sloping land\" or \"financial institution\". \n",
    "\n",
    "(a) \"I deposited my money in the **bank**\" (financial institution)\n",
    "\n",
    "(b) \"I swam from the river **bank**\" (sloping land)\n",
    "\n",
    "In case a) and b) we can determine that the meaning of \"bank\" based on the *context*. To utilize context in a semantic model we use *contextualized word representations*. Previously we worked with *static word representations*, i.e. the representation does not depend on the context. To illustrate we can consider sentences (a) and (b), the word **bank** would have the same static representation in both sentences, which means that it becomes difficult for us to predict its sense. What we want is to create representations that depend on the context, i.e. *contextualized embeddings*. \n",
    "\n",
    "We will create contextualized embeddings with Recurrent Neural Networks. You can read more about recurrent neural netoworks [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). Your overall task in this lab is to create a neural network model that can disambiguate the word sense of 30 different words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import some packages that we need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# our hyperparameters (add more when/if you need them)\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
      "     |████████████████████████████████| 17.0 MB 3.7 MB/s            \n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "     |████████████████████████████████| 11.6 MB 3.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in ./.local/lib/python3.10/site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "     |████████████████████████████████| 292 kB 3.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in ./.local/lib/python3.10/site-packages (from seaborn) (1.23.0)\n",
      "Collecting scipy>=1.0\n",
      "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
      "     |████████████████████████████████| 42.2 MB 28.0 MB/s            \n",
      "\u001b[?25hCollecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n",
      "     |████████████████████████████████| 11.9 MB 87.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23 in ./.local/lib/python3.10/site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.local/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "     |████████████████████████████████| 1.6 MB 95.3 MB/s            \n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     |████████████████████████████████| 3.1 MB 88.7 MB/s            \n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3.10/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "     |████████████████████████████████| 930 kB 93.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/lib/python3.10/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, scipy, matplotlib, seaborn\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.3 matplotlib-3.5.2 pillow-9.1.1 scipy-1.8.1 seaborn-0.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other packages that we are going to use\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with data\n",
    "\n",
    "A central part of any machine learning system is the data we're working with. In this section we will split the data (the dataset is located here: ``wsd-data/wsd_data.txt``) into a training set and a test set. We will also create a baseline to compare our model against. Finally, we will use TorchText to transform our data (raw text) into a convenient format that our neural network can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset we will use contain different word sense for 30 different words. The data is organized as follows (values separated by tabs): \n",
    "- Column 1: word-sense\n",
    "- Column 2: word-form\n",
    "- Column 3: index of word\n",
    "- Column 4: white-space tokenized context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "Your first task is to seperate the data into a *training set* and a *test set*. The training set should contain 80% of the examples and the test set the remaining 20%. The examples for the test/training set should be selected **randomly**. Save each dataset into a .csv file for loading later. **[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT RE-RUN THESE CELLS!  \n",
    "They are here ONLY to make the data split once and save it. Re-running them will mess up the data split and will render them useless for testing anything on the saved BERT model. Continue from \"creating a baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(path_to_dataset):\n",
    "    # your code goes here\n",
    "    with open(path_to_dataset) as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    clean_lines = []\n",
    "    for line in lines:\n",
    "        clean_line = line.strip().split(\"\\t\")\n",
    "        clean_lines.append(clean_line)\n",
    "        \n",
    "    shuffled_lines = random.sample(clean_lines, len(clean_lines))\n",
    "    \n",
    "    # it will not be an exact 80/20 unless the set allows for it, this way the training set is marginally larger than 80%\n",
    "    training_cutoff = math.ceil(len(clean_lines)*0.8)  \n",
    "    \n",
    "    training = shuffled_lines[:training_cutoff]\n",
    "    testing = shuffled_lines[training_cutoff:]\n",
    "        \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_split('wsd_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60840\n",
      "15209\n",
      "0.1999894804665413\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "\n",
    "print(len(test)/(len(test)+len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_save(train, test, train_file, test_file):\n",
    "    \n",
    "    with open(train_file, 'w', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(train)\n",
    "        \n",
    "    with open(test_file, 'w', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save(train, test, 'wsd_train.csv', 'wsd_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wsd_test.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    rows = []\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "        \n",
    "for row in rows:\n",
    "    if len(row) != 4:\n",
    "        print(\"oopsie, your file does not work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a baseline\n",
    "\n",
    "Your second task is to create a *baseline* for the task. A baseline is a \"reality check\" for a model, given a very simple heuristic/algorithmic/model solution to the problem, can our neural network perform better than this?\n",
    "The baseline you are to create is the \"most common sense\" (MCS) baseline. For each word form, find the most commonly assigned sense to the word, and label a words with that sense. **[2 marks]**\n",
    "\n",
    "E.g. In a fictional dataset, \"bank\" have two senses, \"financial institution\" which occur 5 times and \"side of river\" 3 times. Thus, all 8 occurences of bank is labeled \"financial institution\" and this yields an MCS accuracy of 5/8 = 62.5%. If a model obtain a higher score than this, we can conclude that the model *at least* is better than selecting the most frequent word sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('wsd_train.csv', header=None)\n",
    "train_data.columns = ['word-sense', 'word-form', 'index', 'context']\n",
    "test_data = pd.read_csv('wsd_test.csv', header=None)\n",
    "test_data.columns = ['word-sense', 'word-form', 'index', 'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcs_baseline_2(train_data, test_data):\n",
    "    msc_mapping = {}\n",
    "    for word_form, df in train_data.groupby('word-form'):\n",
    "        msc_mapping[word_form] = df['word-sense'].value_counts().idxmax()\n",
    "\n",
    "    #'missing' incase (unlikely) all observations of one word-form ends up in test_data.\n",
    "    msc_test_results = test_data['word-form'].apply(lambda x: msc_mapping.get(x, 'missing'))\n",
    "\n",
    "    #return msc_test_results\n",
    "    accuracy = np.sum(msc_test_results == test_data['word-sense'])/len(test_data)\n",
    "    return accuracy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSC Baseline Accuracy: 31.09%\n"
     ]
    }
   ],
   "source": [
    "print(f'MSC Baseline Accuracy: {round(mcs_baseline_2(train_data, test_data)*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two yield similar results, but there is a bit of a difference between them, which is why we wanted to show both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens if we remove the word from the word sense? \n",
    "Example: keep%2:42:07:: -> 2:42:07::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wsd_data.txt', sep='\\t', header=None)\n",
    "data.columns = ['word-sense', 'word-form', 'index', 'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will be needed for getting per-word-form accuracy\n",
    "def get_wf(w):\n",
    "    # keep%2:42:07:: -> keep\n",
    "    splt = w.split('%')\n",
    "    if len(splt)!=2:\n",
    "        raise Exception('Unknown word-sense format')\n",
    "    return splt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "def remove_word(w):\n",
    "    # keep%2:42:07:: -> 2:42:07::\n",
    "    splt = w.split('%')\n",
    "    if len(splt)!=2:\n",
    "        raise Exception('Unknown word-sense format')\n",
    "    return splt[-1]\n",
    "\n",
    "print(len(np.unique(data['word-sense'])))\n",
    "print(len(np.unique(data['word-sense'].apply(remove_word))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word-sense-generalized'] = data['word-sense'].apply(remove_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation/Idea: From 222 unique instances to 135, i.e there is some overlap between the word-sense codes. The result implies that we can possibly improve generalization by removing the word from word-sense. As the word itself is not unknown and can be readded after prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data iterators\n",
    "\n",
    "To train a neural network, we first need to prepare the data. This involves converting words (and labels) to a number, and organizing the data into batches. We also want the ability to shuffle the examples such that they appear in a random order.  \n",
    "\n",
    "To do all of this we will use the torchtext library (https://torchtext.readthedocs.io/en/latest/index.html). In addition to converting our data into numerical form and creating batches, it will generate a word and label vocabulary, and data iterators than can sort and shuffle the examples. \n",
    "\n",
    "Your task is to create a dataloader for the training and test set you created previously. So, how do we go about doing this?\n",
    "\n",
    "1) First we create a ``Field`` for each of our columns. A field is a function which tokenize the input, keep a dictionary of word-to-numbers, and fix paddings. So, we need four fields, one for the word-sense, one for the position, one for the lemma and one for the context. \n",
    "\n",
    "2) After we have our fields, we need to process the data. For this we use the ``TabularDataset`` class. We pass the name and path of the training and test files we created previously, then we assign which field to use in each column. The result is that each column will be processed by the field indicated. So, the context column will be tokenized and processed by the context field and so on. \n",
    "\n",
    "3) After we have processed the dataset we need to build the vocabulary, for this we call the function ``build_vocab()`` on the different ``Fields`` with the output from ``TabularDataset`` as input. This looks at our dataset and creates the necessary vocabularies (word-to-number mappings). \n",
    "\n",
    "4) Finally, the last step. In the last step we load the data objects given by the ``TabularDataset`` and pass it to the ``BucketIterator`` class. This class will organize our examples into batches and shuffle them around (such that for each epoch the model observe the examples in a different order). When we are done with this we can let our function return the data iterators and vocabularies, then we are ready to train and test our model!\n",
    "\n",
    "Implement the dataloader. [**2 marks**]\n",
    "\n",
    "*hint: for TabularDataset and BucketIterator use the class function splits()* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not use torchtext as in the class it was suggested that doing custom datasets and loaders is an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I implement a Dataset to keep track of vocab, word2idx, idx2word\n",
    "# Dataset can also be used in DataLoader which gives batch loading, etc, for free.\n",
    "\n",
    "class WSDDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, unk_label='<unk>', pad_label='<pad>', generalize_word_sense=False):\n",
    "        \n",
    "        self.unk_idx, self.unk_label = 0, unk_label\n",
    "        self.pad_idx, self.pad_label = 1, pad_label\n",
    "\n",
    "        self.data = data.copy()\n",
    "        self.data['context'] = self.data['context'].apply(self.tokenize)\n",
    "        if generalize_word_sense:\n",
    "            self.data['word-sense'] = self.data['word-sense'].apply(self.__remove_word)\n",
    "\n",
    "        self.vocab = self.__unique_words()\n",
    "        \n",
    "        self.word2idx = dict()\n",
    "        self.idx2word = dict()\n",
    "        self.word2idx[self.unk_label] = self.unk_idx\n",
    "        self.word2idx[self.pad_label] = self.pad_idx\n",
    "        self.word2idx.update({word:idx+max(self.word2idx.values())+1 for idx, word in enumerate(self.vocab)})\n",
    "\n",
    "        self.idx2word = {v:k for k,v in self.word2idx.items()}\n",
    "\n",
    "        self.labels = list(np.unique(self.data['word-sense']))\n",
    "\n",
    "    def __unique_words(self):\n",
    "        all_words = []\n",
    "        for s in self.data['context']:\n",
    "            all_words += s\n",
    "        return np.unique(all_words)\n",
    "        \n",
    "    def tokenize(self, string):\n",
    "        # The tokenizer was given as a whitespace tokenizer\n",
    "        return string.lower().split()\n",
    "\n",
    "    # generalized word-sense tags\n",
    "    def __remove_word(self, w):\n",
    "        # keep%2:42:07:: -> 2:42:07::\n",
    "        splt = w.split('%')\n",
    "        if len(splt)!=2:\n",
    "            raise Exception('Unknown word-sense format')\n",
    "        return splt[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #x = self.data.iloc[0] #for test\n",
    "        x = self.data.iloc[idx]\n",
    "        out = (x['index'], x['context'], x['word-sense'])\n",
    "        return out\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from torch.nn.utils.rnn import pad_sequence \n",
    "\n",
    "word_sense_to_idx = {k:v for v,k in enumerate(sorted(np.unique(data['word-sense'])))}\n",
    "idx_to_word_sense = {v:k for k,v in word_sense_to_idx.items()}\n",
    "\n",
    "class Collate():\n",
    "    def __init__(self, word_to_idx, pad_idx=1, unk_idx=0, word_sense_to_idx=word_sense_to_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.unk_idx = unk_idx\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.word_sense_to_idx = word_sense_to_idx\n",
    "    def __call__(self, batch):\n",
    "        batch = np.transpose(batch)\n",
    "        indices = batch[0]\n",
    "        word_senses = [self.word_sense_to_idx[ws] for ws in batch[2]]\n",
    "\n",
    "        contexts = np.transpose(batch[1]) #batch first\n",
    "        contexts = [torch.tensor([self.word_to_idx.get(w, self.unk_idx) for w in s], device=device) for s in contexts]\n",
    "        contexts = pad_sequence(contexts, batch_first=True, padding_value=self.pad_idx)\n",
    "            \n",
    "        return indices, contexts, word_senses\n",
    "\n",
    "\n",
    "def dataloader(dataset, word2idx, pad_idx, unk_idx, batch_size=32, shuffle=True): # Need word2idx etc to match between train and test. Id probably do this is another wya in hindsight.\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=Collate(word2idx, pad_idx, unk_idx) )\n",
    "    return loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word-sense</th>\n",
       "      <th>word-form</th>\n",
       "      <th>index</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see%2:39:02::</td>\n",
       "      <td>see.v</td>\n",
       "      <td>48</td>\n",
       "      <td>During the day , rumours had circulated that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>follow%2:38:01::</td>\n",
       "      <td>follow.v</td>\n",
       "      <td>21</td>\n",
       "      <td>Work programme of the Commission for the remai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>major%3:00:07::</td>\n",
       "      <td>major.a</td>\n",
       "      <td>47</td>\n",
       "      <td>Average per capita expenditure has plummeted f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>professional%3:00:01::</td>\n",
       "      <td>professional.a</td>\n",
       "      <td>21</td>\n",
       "      <td>There were approximately 400 outpatient clinic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word-sense       word-form  index  \\\n",
       "0           see%2:39:02::           see.v     48   \n",
       "1        follow%2:38:01::        follow.v     21   \n",
       "2         major%3:00:07::         major.a     47   \n",
       "3  professional%3:00:01::  professional.a     21   \n",
       "\n",
       "                                             context  \n",
       "0  During the day , rumours had circulated that t...  \n",
       "1  Work programme of the Commission for the remai...  \n",
       "2  Average per capita expenditure has plummeted f...  \n",
       "3  There were approximately 400 outpatient clinic...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, ['during', 'the', 'day', ',', 'rumours', 'had', 'circulated', 'that', 'those', 'wounded', 'who', 'had', 'been', 'sent', 'to', 'the', 'hospital', 'were', 'also', 'killed', ':', 'one', 'wounded', 'eyewitness', 'transferred', 'to', 'the', 'hospital', 'corroborated', 'this', '.', 'a', 'number', 'of', 'persons', 'interviewed', 'by', 'the', 'ohchr', 'mission', 'noted', 'that', 'a', 'significant', 'part', 'of', 'the', 'soldiers', 'seen', 'during', 'the', 'day', 'were', 'most', 'likely', 'not', 'from', 'andijan', 'or', 'the', 'region.', 'often', 'they', 'were', 'referred', 'to', 'by', 'witnesses', 'as', 'special', 'forces', '(', 'spetsna', ')', '.', 'some', 'even', 'mentioned', 'that', 'the', 'soldiers', 'were', 'significantly', 'taller', 'than', 'those', 'they', 'saw', 'on', 'a', 'daily', 'basis', 'in', 'the', 'city', 'and', 'had', 'a', 'different', 'skin', 'complexion', '.'], 'see%2:39:02::')\n",
      "4\n",
      "uniq word sense ['follow%2:38:01::', 'major%3:00:07::', 'professional%3:00:01::', 'see%2:39:02::']\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "## -- testing dataset--\n",
    "tt = train_data.iloc[0:4].copy()\n",
    "display(tt)\n",
    "\n",
    "tt_dset =  WSDDataset(tt)\n",
    "\n",
    "print(tt_dset[0])\n",
    "\n",
    "print(len(tt_dset))\n",
    "\n",
    "print('uniq word sense', (tt_dset.labels))\n",
    "\n",
    "print(len(tt_dset.word2idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusszawma@GU.GU.SE/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([48, 21, 47], dtype=object), tensor([[ 48, 140,  45,   6, 116,  66,  35, 139, 143, 159, 155,  66,  28, 119,\n",
      "         146, 140,  70, 154,  19,  77,  14,  96, 159,  54, 149, 146, 140,  70,\n",
      "          42, 142,   7,  15,  90,  92, 102,  73,  29, 140,  94,  84,  89, 139,\n",
      "          15, 122,  99,  92, 140, 127, 118,  48, 140,  45, 154,  86,  79,  88,\n",
      "          62,  21,  97, 140, 113,  93, 141, 154, 112, 146,  29, 157,  24, 129,\n",
      "          59,   4, 130,   5,   7, 128,  52,  83, 139, 140, 127, 154, 123, 135,\n",
      "         138, 143, 141, 117,  95,  15,  44,  26,  71, 140,  36,  20,  66,  15,\n",
      "          46, 126,  38,   7],\n",
      "        [158, 109,  92, 140,  37,  58, 140, 114,  92, 140, 111, 124, 142,  74,\n",
      "         140,  56, 160,  92, 140, 111,  20,  57,  76, 153, 104, 140,  37,  60,\n",
      "          75, 152, 146,  51,  15, 158, 109,  58, 140,  50,  61, 161, 120,  98,\n",
      "          71,  63, 137, 140,  64, 156, 115, 146,  49, 147, 146,  27,  16,  48,\n",
      "         142, 101,   7,  75,  74, 140, 150,  92, 140,  37, 139, 142, 158, 109,\n",
      "          67,  15, 136,  34, 124, 140,  87,  20, 140,  39,  92, 140, 158, 105,\n",
      "          22,  33, 106,  15,  80, 145,  71,  17,   7,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1],\n",
      "        [ 25, 100,  30,  53,  67, 103,  62, 151,   2,  13,  71,   9, 146,  23,\n",
      "         151,   2,  11,  71,  10,   7, 140,  81,  92,  85, 138,   8, 100,  32,\n",
      "          92, 140,  43,   3,  47,  20,  12, 100,  32,  92,  76,  91,  48, 140,\n",
      "          78, 125, 161,  67,  31,  82, 131, 121,  20,  40, 107, 132,   7,  72,\n",
      "          18,  68,  41, 146, 133, 140,  65,  92, 134, 144, 140, 110,  92,  55,\n",
      "          20, 148,  58,  69, 108,   7,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1]], device='cuda:3'), [204, 63, 133])\n"
     ]
    }
   ],
   "source": [
    "# -- test data loader ---\n",
    "tt2 = train_data.iloc[0:3].copy()\n",
    "tt2 =  WSDDataset(tt2)\n",
    "\n",
    "loader = dataloader(tt2, tt2.word2idx, tt2.pad_idx, tt2.unk_idx, batch_size=3,shuffle=False)\n",
    "for b in loader:\n",
    "    #print()\n",
    "    print(b)\n",
    "\n",
    "## Note: I should probably clump together contexts of small, medium and large size to reduce padding. I remember Nikolai talking about this in a previous course.\n",
    "# Its possible that BatchIterator does this automatically which would be an advantage of using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204, 63, 133]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 102])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(b[2])\n",
    "b[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Creating and running a Neural Network for WSD\n",
    "\n",
    "In this section we will create and run a neural network to predict word senses based on *contextualized representations*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We will use a bidirectional Long-Short-Term Memory (LSTM) network to create a representation for the sentences and a Linear classifier to predict the sense of each word.\n",
    "\n",
    "When we initialize the model, we need a few things:\n",
    "\n",
    "    1) An embedding layer: a dictionary from which we can obtain word embeddings\n",
    "    2) A LSTM-module to obtain contextual representations\n",
    "    3) A classifier that compute scores for each word-sense given *some* input\n",
    "\n",
    "\n",
    "The general procedure is the following:\n",
    "\n",
    "    1) For each word in the sentence, obtain word embeddings\n",
    "    2) Run the embedded sentences through the RNN\n",
    "    3) Select the appropriate hidden state\n",
    "    4) Predict the word-sense \n",
    "\n",
    "**Suggestion for efficiency:**  *Use a low dimensionality (32) for word embeddings and the LSTM when developing and testing the code, then scale up when running the full training/tests*\n",
    "    \n",
    "Your tasks will be to create two different models (both follow the two outlines described above), described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first approach to WSD, you are to select the index of our target word (column 3 in the dataset) and predict the word sense. **[5 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSDModel_approach1(nn.Module): \n",
    "    def __init__(self, word2idx, wordsense2idx, embedding_dim=32, hidden_size=128,padding_idx=1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(word2idx)\n",
    "        self.output_dim = len(wordsense2idx)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # your code goes here\n",
    "        self.embeddings = nn.Embedding(self.vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.LSTM = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_size, num_layers=1, bidirectional=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size*2, self.output_dim)\n",
    "    \n",
    "    def forward(self, contexts, indices):\n",
    "        # your code goes here\n",
    "        embedded_contexts = self.embeddings(contexts)\n",
    "\n",
    "        timestep_representation, *_ = self.LSTM(embedded_contexts)\n",
    "\n",
    "        timestep_representation = torch.stack(\n",
    "            [tp[i] for i, tp in zip(indices, timestep_representation)])\n",
    "\n",
    "        # Didnt have time to work this out... \n",
    "        # Adam: Dont use for loops and tensors! \n",
    "        #timestep_representation = timestep_representation[torch.arange(timestep_representation.size(0)), torch.tensor(indices).int()]\n",
    "        # how to do it better?\n",
    "        \n",
    "        # Was the issue with not taking into account bidirectionality? But\n",
    "        # the first timestep_representation already has the suitable shape\n",
    "        # 32 (batch size) by 256 (2 x hidden size), our assumption was it \n",
    "        # automatically concatenates them\n",
    "        \n",
    "        predictions = self.classifier(timestep_representation)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second approach to WSD, you are to predict the word sense based on the final hidden state given by the RNN. **[5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSDModel_approach2(nn.Module):\n",
    "    def __init__(self, word2idx, wordsense2idx, embedding_dim=32, hidden_size=128, padding_idx=1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(word2idx)\n",
    "        self.output_dim = len(wordsense2idx)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # your code goes here\n",
    "        self.embeddings = nn.Embedding(\n",
    "            self.vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.LSTM = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=self.hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size*2, self.output_dim)\n",
    "\n",
    "    def forward(self, contexts):\n",
    "        # your code goes here\n",
    "        embedded_contexts = self.embeddings(contexts)\n",
    "\n",
    "        timestep_representation, (final_hidden, final_cell) = self.LSTM(embedded_contexts)\n",
    "        hidden = torch.cat((final_hidden[0, :, :], final_hidden[1, :, :]), dim=1)\n",
    "        # timestep_representation = torch.stack([tp[i] for i, tp in zip(indices, timestep_representation)])\n",
    "\n",
    "        predictions = self.classifier(hidden)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the model\n",
    "\n",
    "Now we are ready to train and test our model. What we need now is a loss function, an optimizer, and our data. \n",
    "\n",
    "- First, create the loss function and the optimizer.\n",
    "- Next, we iterate over the number of epochs (i.e. how many times we let the model see our data). \n",
    "- For each epoch, iterate over the dataset (``train_iter``) to obtain batches. Use the batch as input to the model, and let the model output scores for the different word senses.\n",
    "- For each model output, calculate the loss (and print the loss) on the output and update the model parameters.\n",
    "- Reset the gradients and repeat.\n",
    "- After all epochs are done, test your trained model on the test set (``test_iter``) and calculate the total and per-word-form accuracy of your model.\n",
    "\n",
    "Implement the training and testing of the model **[4 marks]**\n",
    "\n",
    "**Suggestion for efficiency:** *when developing your model, try training and testing the model on one or two batches (for each epoch) of data to make sure everything works! It's very annoying if you train for N epochs to find out that something went wrong when testing the model, or to find that something goes wrong when moving from epoch 0 to epoch 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WSDDataset(train_data)\n",
    "# is the test dataset encoded using the same indices? \n",
    "test_dataset = WSDDataset(test_data)\n",
    "\n",
    "vocab = train_dataset.vocab\n",
    "labels = train_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0 : Average Loss = 5.46776\n",
      " Batch 250 : Average Loss = 3.93992\n",
      " Batch 500 : Average Loss = 3.01666\n",
      " Batch 750 : Average Loss = 2.59779\n",
      " Batch 1000 : Average Loss = 2.3627\n",
      " Batch 1250 : Average Loss = 2.21183\n",
      " Batch 1500 : Average Loss = 2.10563\n",
      " Batch 1750 : Average Loss = 2.02684\n",
      "Epoch 1 : Average Training Loss = 1.99012\n",
      "Epoch 1 : Test Accuracy = 0.38944\n",
      " Batch 0 : Average Loss = 1.59686\n",
      " Batch 250 : Average Loss = 1.55523\n",
      " Batch 500 : Average Loss = 1.54848\n",
      " Batch 750 : Average Loss = 1.54955\n",
      " Batch 1000 : Average Loss = 1.55346\n",
      " Batch 1250 : Average Loss = 1.5493\n",
      " Batch 1500 : Average Loss = 1.54903\n",
      " Batch 1750 : Average Loss = 1.54796\n",
      "Epoch 2 : Average Training Loss = 1.54639\n",
      "Epoch 2 : Test Accuracy = 0.37918\n"
     ]
    }
   ],
   "source": [
    "# NOTE: We noticed that the model appears to overfit already after a few epochs. - Dropout?! \n",
    "\n",
    "params = {'lr':0.001, 'batch_size':32, 'hidden_size':64, 'embedding_dim':32, 'epochs':2} \n",
    "\n",
    "model = WSDModel_approach1(train_dataset.word2idx, labels, \n",
    "                           embedding_dim=params['embedding_dim'],\n",
    "                           hidden_size=params['hidden_size']\n",
    "                          )\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "for epoch in range(1,params['epochs']+1):\n",
    "    \n",
    "    train_iter = dataloader(train_dataset, train_dataset.word2idx, train_dataset.pad_idx, train_dataset.unk_idx, batch_size=params['batch_size'])\n",
    "    test_iter = dataloader(test_dataset, train_dataset.word2idx, train_dataset.pad_idx, train_dataset.unk_idx, batch_size=128)\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        \n",
    "        if True: #i < 50: # For testing\n",
    "            contexts = batch[1]\n",
    "            indices = batch[0]\n",
    "            # this causes an error when we run it on cuda, not on cpu!!!\n",
    "            word_senses = torch.Tensor(batch[2]).long().to(device)\n",
    "            \n",
    "            # send your batch of sentences to the model\n",
    "\n",
    "            output = model(contexts, indices)\n",
    "            # output = model(contexts)\n",
    "            \n",
    "            loss = loss_function(output, word_senses)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if i%250==0:\n",
    "                print(f' Batch {i} : Average Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "            \n",
    "            # calculate gradients\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {epoch} : Average Training Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        per_wf_counts = {}\n",
    "        per_wf_correct = {}\n",
    "        correct = 0\n",
    "        for batch in test_iter:\n",
    "            test_output = model(batch[1], batch[0])\n",
    "            # test_output = model(batch[1])\n",
    "            test_output = torch.argmax(test_output, dim=1)\n",
    "            targets = torch.tensor(batch[2], device=device)\n",
    "            correct += torch.sum(test_output == targets)\n",
    "\n",
    "\n",
    "            # -- per wf stuff ---\n",
    "            # Technically we only need to do this for the last epoch\n",
    "            word_senses = [idx_to_word_sense[j] for j in batch[2]]\n",
    "            words = np.array([ws.split('%')[0] for ws in word_senses])\n",
    "\n",
    "            for w in np.unique(words):\n",
    "                wf_output = test_output[words==w]\n",
    "                wf_targets = targets[words==w]\n",
    "                if w not in per_wf_counts:\n",
    "                    per_wf_counts[w] = np.sum(words==w)\n",
    "                    per_wf_correct[w] =  torch.sum(wf_output == wf_targets)\n",
    "                else:\n",
    "                    per_wf_counts[w] += np.sum(words==w)\n",
    "                    per_wf_correct[w] +=  torch.sum(wf_output == wf_targets)\n",
    "\n",
    "        test_accu = correct/len(test_dataset)\n",
    "        wf_acc = {w:float(per_wf_correct[w]/per_wf_counts[w]) for w in per_wf_correct.keys()}\n",
    "\n",
    "    print(f'Epoch {epoch} : Test Accuracy = {round(float(test_accu), 5)}')\n",
    "\n",
    "df_wf_acc = pd.Series(wf_acc).apply(lambda x: round(x,3))\n",
    "df_wf_acc.name = 'accuracy'\n",
    "df_wf_acc = df_wf_acc.to_frame()\n",
    "data['words'] = data['word-sense'].apply(lambda x: x.split('%')[0]) # I could just use word-form from the start. Yeye i forgot this column\n",
    "df_wf_acc['number_of_senses'] = data.groupby('words')['word-sense'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 2 : Average Training Loss = 1.54639\n",
    "#Epoch 2 : Test Accuracy = 0.37918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>number_of_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.671</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.225</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.293</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.341</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.199</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.323</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.332</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.280</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.303</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.269</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.268</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.372</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.289</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.349</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.332</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.232</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.259</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.295</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.232</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.591</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.227</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.220</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.207</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.403</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.587</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.222</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.246</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.609</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.861</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  number_of_senses\n",
       "bad              0.671                 4\n",
       "common           0.225                 4\n",
       "major            0.293                 4\n",
       "active           0.341                 5\n",
       "professional     0.199                 5\n",
       "positive         0.323                 5\n",
       "order            0.332                 5\n",
       "time             0.280                 5\n",
       "critical         0.303                 5\n",
       "position         0.269                 6\n",
       "national         0.075                 6\n",
       "physical         0.268                 6\n",
       "security         0.372                 7\n",
       "extend           0.289                 7\n",
       "place            0.349                 7\n",
       "case             0.332                 8\n",
       "force            0.232                 8\n",
       "regular          0.259                 8\n",
       "bring            0.295                 8\n",
       "lead             0.232                 8\n",
       "point            0.591                 8\n",
       "life             0.227                 9\n",
       "serve            0.220                 9\n",
       "build            0.207                10\n",
       "find             0.403                10\n",
       "keep             0.587                11\n",
       "hold             0.222                11\n",
       "follow           0.246                11\n",
       "see              0.609                11\n",
       "line             0.861                11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wf_acc = df_wf_acc.sort_values(by='number_of_senses')\n",
    "df_wf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusszawma@GU.GU.SE/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Batch 0 : Average Loss = 5.41508\n",
      " Batch 250 : Average Loss = 5.04004\n",
      " Batch 500 : Average Loss = 4.99985\n",
      " Batch 750 : Average Loss = 4.98302\n",
      " Batch 1000 : Average Loss = 4.96717\n",
      " Batch 1250 : Average Loss = 4.95108\n",
      " Batch 1500 : Average Loss = 4.93783\n",
      " Batch 1750 : Average Loss = 4.92595\n",
      "Epoch 1 : Average Training Loss = 4.91829\n",
      "Epoch 1 : Test Accuracy = 0.08672\n",
      " Batch 0 : Average Loss = 4.75842\n",
      " Batch 250 : Average Loss = 4.84502\n",
      " Batch 500 : Average Loss = 4.88855\n",
      " Batch 750 : Average Loss = 4.89804\n",
      " Batch 1000 : Average Loss = 4.88764\n",
      " Batch 1250 : Average Loss = 4.87256\n",
      " Batch 1500 : Average Loss = 4.85322\n",
      " Batch 1750 : Average Loss = 4.83096\n",
      "Epoch 2 : Average Training Loss = 4.81653\n",
      "Epoch 2 : Test Accuracy = 0.11276\n",
      " Batch 0 : Average Loss = 4.5837\n",
      " Batch 250 : Average Loss = 4.56684\n",
      " Batch 500 : Average Loss = 4.55525\n",
      " Batch 750 : Average Loss = 4.54736\n",
      " Batch 1000 : Average Loss = 4.53758\n",
      " Batch 1250 : Average Loss = 4.52066\n",
      " Batch 1500 : Average Loss = 4.49614\n",
      " Batch 1750 : Average Loss = 4.47121\n",
      "Epoch 3 : Average Training Loss = 4.45641\n",
      "Epoch 3 : Test Accuracy = 0.15945\n",
      " Batch 0 : Average Loss = 4.26654\n",
      " Batch 250 : Average Loss = 4.24823\n",
      " Batch 500 : Average Loss = 4.21439\n",
      " Batch 750 : Average Loss = 4.18257\n",
      " Batch 1000 : Average Loss = 4.14264\n",
      " Batch 1250 : Average Loss = 4.09983\n",
      " Batch 1500 : Average Loss = 4.06309\n",
      " Batch 1750 : Average Loss = 4.02306\n",
      "Epoch 4 : Average Training Loss = 3.99903\n",
      "Epoch 4 : Test Accuracy = 0.21356\n",
      " Batch 0 : Average Loss = 3.74067\n",
      " Batch 250 : Average Loss = 3.60466\n",
      " Batch 500 : Average Loss = 3.57829\n",
      " Batch 750 : Average Loss = 3.55549\n",
      " Batch 1000 : Average Loss = 3.51608\n",
      " Batch 1250 : Average Loss = 3.47462\n",
      " Batch 1500 : Average Loss = 3.43155\n",
      " Batch 1750 : Average Loss = 3.39074\n",
      "Epoch 5 : Average Training Loss = 3.37005\n",
      "Epoch 5 : Test Accuracy = 0.28536\n",
      " Batch 0 : Average Loss = 3.50316\n",
      " Batch 250 : Average Loss = 2.99207\n",
      " Batch 500 : Average Loss = 2.96671\n",
      " Batch 750 : Average Loss = 2.94906\n",
      " Batch 1000 : Average Loss = 2.93163\n",
      " Batch 1250 : Average Loss = 2.91215\n",
      " Batch 1500 : Average Loss = 2.89217\n",
      " Batch 1750 : Average Loss = 2.86765\n",
      "Epoch 6 : Average Training Loss = 2.84986\n",
      "Epoch 6 : Test Accuracy = 0.32284\n",
      " Batch 0 : Average Loss = 1.81257\n",
      " Batch 250 : Average Loss = 2.60977\n",
      " Batch 500 : Average Loss = 2.58684\n",
      " Batch 750 : Average Loss = 2.57822\n",
      " Batch 1000 : Average Loss = 2.56462\n",
      " Batch 1250 : Average Loss = 2.55081\n",
      " Batch 1500 : Average Loss = 2.53719\n",
      " Batch 1750 : Average Loss = 2.51624\n",
      "Epoch 7 : Average Training Loss = 2.51181\n",
      "Epoch 7 : Test Accuracy = 0.3586\n",
      " Batch 0 : Average Loss = 2.1966\n",
      " Batch 250 : Average Loss = 2.33324\n",
      " Batch 500 : Average Loss = 2.30557\n",
      " Batch 750 : Average Loss = 2.29195\n",
      " Batch 1000 : Average Loss = 2.27882\n",
      " Batch 1250 : Average Loss = 2.25852\n",
      " Batch 1500 : Average Loss = 2.2446\n",
      " Batch 1750 : Average Loss = 2.23016\n",
      "Epoch 8 : Average Training Loss = 2.22116\n",
      "Epoch 8 : Test Accuracy = 0.39628\n",
      " Batch 0 : Average Loss = 2.59845\n",
      " Batch 250 : Average Loss = 2.00583\n",
      " Batch 500 : Average Loss = 2.00392\n",
      " Batch 750 : Average Loss = 2.00598\n",
      " Batch 1000 : Average Loss = 1.99706\n",
      " Batch 1250 : Average Loss = 1.99274\n",
      " Batch 1500 : Average Loss = 1.98863\n",
      " Batch 1750 : Average Loss = 1.97927\n",
      "Epoch 9 : Average Training Loss = 1.97393\n",
      "Epoch 9 : Test Accuracy = 0.41811\n",
      " Batch 0 : Average Loss = 1.68985\n",
      " Batch 250 : Average Loss = 1.78935\n",
      " Batch 500 : Average Loss = 1.78454\n",
      " Batch 750 : Average Loss = 1.77734\n",
      " Batch 1000 : Average Loss = 1.77837\n",
      " Batch 1250 : Average Loss = 1.77985\n",
      " Batch 1500 : Average Loss = 1.77317\n",
      " Batch 1750 : Average Loss = 1.76749\n",
      "Epoch 10 : Average Training Loss = 1.7642\n",
      "Epoch 10 : Test Accuracy = 0.43455\n",
      " Batch 0 : Average Loss = 1.73533\n",
      " Batch 250 : Average Loss = 1.60112\n",
      " Batch 500 : Average Loss = 1.60258\n",
      " Batch 750 : Average Loss = 1.60848\n",
      " Batch 1000 : Average Loss = 1.60141\n",
      " Batch 1250 : Average Loss = 1.59095\n",
      " Batch 1500 : Average Loss = 1.59231\n",
      " Batch 1750 : Average Loss = 1.59212\n",
      "Epoch 11 : Average Training Loss = 1.59418\n",
      "Epoch 11 : Test Accuracy = 0.45467\n",
      " Batch 0 : Average Loss = 1.3212\n",
      " Batch 250 : Average Loss = 1.46999\n",
      " Batch 500 : Average Loss = 1.45964\n",
      " Batch 750 : Average Loss = 1.4659\n",
      " Batch 1000 : Average Loss = 1.47008\n",
      " Batch 1250 : Average Loss = 1.4687\n",
      " Batch 1500 : Average Loss = 1.46313\n",
      " Batch 1750 : Average Loss = 1.45738\n",
      "Epoch 12 : Average Training Loss = 1.45517\n",
      "Epoch 12 : Test Accuracy = 0.47051\n",
      " Batch 0 : Average Loss = 1.62785\n",
      " Batch 250 : Average Loss = 1.30944\n",
      " Batch 500 : Average Loss = 1.3238\n",
      " Batch 750 : Average Loss = 1.3222\n",
      " Batch 1000 : Average Loss = 1.32511\n",
      " Batch 1250 : Average Loss = 1.33059\n",
      " Batch 1500 : Average Loss = 1.33361\n",
      " Batch 1750 : Average Loss = 1.33405\n",
      "Epoch 13 : Average Training Loss = 1.33397\n",
      "Epoch 13 : Test Accuracy = 0.47584\n",
      " Batch 0 : Average Loss = 1.25016\n",
      " Batch 250 : Average Loss = 1.23691\n",
      " Batch 500 : Average Loss = 1.22406\n",
      " Batch 750 : Average Loss = 1.21875\n",
      " Batch 1000 : Average Loss = 1.2161\n",
      " Batch 1250 : Average Loss = 1.21844\n",
      " Batch 1500 : Average Loss = 1.21985\n",
      " Batch 1750 : Average Loss = 1.22135\n",
      "Epoch 14 : Average Training Loss = 1.22364\n",
      "Epoch 14 : Test Accuracy = 0.48392\n",
      " Batch 0 : Average Loss = 1.18138\n",
      " Batch 250 : Average Loss = 1.12019\n",
      " Batch 500 : Average Loss = 1.11503\n",
      " Batch 750 : Average Loss = 1.11342\n",
      " Batch 1000 : Average Loss = 1.11776\n",
      " Batch 1250 : Average Loss = 1.11952\n",
      " Batch 1500 : Average Loss = 1.12062\n",
      " Batch 1750 : Average Loss = 1.12232\n",
      "Epoch 15 : Average Training Loss = 1.124\n",
      "Epoch 15 : Test Accuracy = 0.4953\n",
      " Batch 0 : Average Loss = 1.09847\n",
      " Batch 250 : Average Loss = 1.0126\n",
      " Batch 500 : Average Loss = 1.01803\n",
      " Batch 750 : Average Loss = 1.02881\n",
      " Batch 1000 : Average Loss = 1.0206\n",
      " Batch 1250 : Average Loss = 1.02573\n",
      " Batch 1500 : Average Loss = 1.02737\n",
      " Batch 1750 : Average Loss = 1.03024\n",
      "Epoch 16 : Average Training Loss = 1.03339\n",
      "Epoch 16 : Test Accuracy = 0.50569\n",
      " Batch 0 : Average Loss = 1.10255\n",
      " Batch 250 : Average Loss = 0.91607\n",
      " Batch 500 : Average Loss = 0.92017\n",
      " Batch 750 : Average Loss = 0.91939\n",
      " Batch 1000 : Average Loss = 0.92892\n",
      " Batch 1250 : Average Loss = 0.93466\n",
      " Batch 1500 : Average Loss = 0.93897\n",
      " Batch 1750 : Average Loss = 0.94345\n",
      "Epoch 17 : Average Training Loss = 0.94721\n",
      "Epoch 17 : Test Accuracy = 0.49464\n",
      " Batch 0 : Average Loss = 0.79629\n",
      " Batch 250 : Average Loss = 0.82897\n",
      " Batch 500 : Average Loss = 0.85068\n",
      " Batch 750 : Average Loss = 0.84464\n",
      " Batch 1000 : Average Loss = 0.8498\n",
      " Batch 1250 : Average Loss = 0.85787\n",
      " Batch 1500 : Average Loss = 0.86545\n",
      " Batch 1750 : Average Loss = 0.86876\n",
      "Epoch 18 : Average Training Loss = 0.86915\n",
      "Epoch 18 : Test Accuracy = 0.49504\n"
     ]
    }
   ],
   "source": [
    "# This approach takes longer to train. In practice youd keep track and store the model at the optimal\n",
    "# testing/validation criterion. \n",
    "params = {'lr':0.001, 'batch_size':32, 'hidden_size':64, 'embedding_dim':32, 'epochs':18} \n",
    "\n",
    "model = WSDModel_approach2(train_dataset.word2idx, labels, \n",
    "                           embedding_dim=params['embedding_dim'],\n",
    "                           hidden_size=params['hidden_size']\n",
    "                          )\n",
    "model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "\n",
    "for epoch in range(1,params['epochs']+1):\n",
    "    \n",
    "    train_iter = dataloader(train_dataset, train_dataset.word2idx, train_dataset.pad_idx, train_dataset.unk_idx, batch_size=params['batch_size'])\n",
    "    test_iter = dataloader(test_dataset, train_dataset.word2idx, train_dataset.pad_idx, train_dataset.unk_idx, batch_size=128)\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(train_iter):\n",
    "        \n",
    "        if True: #i < 50: # For testing\n",
    "            contexts = batch[1]\n",
    "            indices = batch[0]\n",
    "            # this causes an error when we run it on cuda, not on cpu!!!\n",
    "            word_senses = torch.Tensor(batch[2]).long().to(device)\n",
    "            \n",
    "            # send your batch of sentences to the model\n",
    "\n",
    "            # output = model(contexts, indices)\n",
    "            output = model(contexts)\n",
    "            \n",
    "            loss = loss_function(output, word_senses)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if i%250==0:\n",
    "                print(f' Batch {i} : Average Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "            \n",
    "            # calculate gradients\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "            # reset gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {epoch} : Average Training Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        per_wf_counts = {}\n",
    "        per_wf_correct = {}\n",
    "        correct = 0\n",
    "        for batch in test_iter:\n",
    "            test_output = model(batch[1])\n",
    "            # test_output = model(batch[1])\n",
    "            test_output = torch.argmax(test_output, dim=1)\n",
    "            targets = torch.tensor(batch[2], device=device)\n",
    "            correct += torch.sum(test_output == targets)\n",
    "\n",
    "\n",
    "            # -- per wf stuff ---\n",
    "            # Technically we only need to do this for the last epoch\n",
    "            word_senses = [idx_to_word_sense[j] for j in batch[2]]\n",
    "            words = np.array([ws.split('%')[0] for ws in word_senses])\n",
    "\n",
    "            for w in np.unique(words):\n",
    "                wf_output = test_output[words==w]\n",
    "                wf_targets = targets[words==w]\n",
    "                if w not in per_wf_counts:\n",
    "                    per_wf_counts[w] = np.sum(words==w)\n",
    "                    per_wf_correct[w] =  torch.sum(wf_output == wf_targets)\n",
    "                else:\n",
    "                    per_wf_counts[w] += np.sum(words==w)\n",
    "                    per_wf_correct[w] +=  torch.sum(wf_output == wf_targets)\n",
    "\n",
    "        test_accu = correct/len(test_dataset)\n",
    "        wf_acc = {w:float(per_wf_correct[w]/per_wf_counts[w]) for w in per_wf_correct.keys()}\n",
    "\n",
    "    print(f'Epoch {epoch} : Test Accuracy = {round(float(test_accu), 5)}')\n",
    "\n",
    "df_wf_acc2 = pd.Series(wf_acc).apply(lambda x: round(x,3))\n",
    "df_wf_acc2.name = 'accuracy'\n",
    "df_wf_acc2 = df_wf_acc2.to_frame()\n",
    "data['words'] = data['word-sense'].apply(lambda x: x.split('%')[0]) # I could just use word-form from the start. Yeye i forgot this column\n",
    "df_wf_acc2['number_of_senses'] = data.groupby('words')['word-sense'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epoch 18 : Average Training Loss = 0.86915\n",
    "#Epoch 18 : Test Accuracy = 0.49504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>number_of_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.674</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.385</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.328</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.594</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.442</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.515</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.302</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.390</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.426</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.262</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.515</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.458</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.500</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.417</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.548</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.556</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.276</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.510</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.425</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.477</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.254</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.405</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.659</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.392</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.648</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.879</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  number_of_senses\n",
       "bad              0.674                 4\n",
       "common           0.385                 4\n",
       "major            0.328                 4\n",
       "active           0.547                 5\n",
       "professional     0.594                 5\n",
       "positive         0.442                 5\n",
       "order            0.515                 5\n",
       "time             0.302                 5\n",
       "critical         0.390                 5\n",
       "position         0.426                 6\n",
       "national         0.262                 6\n",
       "physical         0.515                 6\n",
       "place            0.458                 7\n",
       "security         0.500                 7\n",
       "extend           0.463                 7\n",
       "regular          0.417                 8\n",
       "bring            0.336                 8\n",
       "point            0.548                 8\n",
       "force            0.556                 8\n",
       "lead             0.276                 8\n",
       "case             0.311                 8\n",
       "life             0.510                 9\n",
       "serve            0.425                 9\n",
       "find             0.477                10\n",
       "build            0.254                10\n",
       "follow           0.405                11\n",
       "keep             0.659                11\n",
       "hold             0.392                11\n",
       "see              0.648                11\n",
       "line             0.879                11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wf_acc2 = df_wf_acc2.sort_values(by='number_of_senses')\n",
    "df_wf_acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Running a transformer for WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the lab you'll try out the transformer, specifically the BERT model. For this we'll use the huggingface library (https://huggingface.co/).\n",
    "\n",
    "You can find the documentation for the BERT model here (https://huggingface.co/transformers/model_doc/bert.html) and a general usage guide here (https://huggingface.co/transformers/quickstart.html).\n",
    "\n",
    "What we're going to do is *fine-tune* the BERT model, i.e. update the weights of a pre-trained model. That is, we have a model that is trained on language modeling, but now we apply it to word sense disambiguation with the word representations it learnt from language modeling.\n",
    "\n",
    "We'll use the same data splits for training and testing as before, but this time you'll not use a torchtext dataloader. Rather now you create an iterator that collects N sentences (where N is the batch size) then use the BertTokenizer to transform the sentence into integers. For your dataloader, remember to:\n",
    "* Shuffle the data in each batch\n",
    "* Make sure you get a new iterator for each *epoch*\n",
    "* Create a vocabulary of *sense-labels* so you can calculate accuracy \n",
    "\n",
    "We then pass this batch into the BERT model and train as before. The BERT model will encode the sentence, then we send this encoded sentence into a prediction layer (you can either the the sentence-representation from bert, or the ambiguous word) like before and collect sense predictions.\n",
    "\n",
    "About the hyperparameters and training:\n",
    "* For BERT, usually a lower learning rate works best, between 0.0001-0.000001.\n",
    "* BERT takes alot of resources, running it on CPU will take ages, utilize the GPUs :)\n",
    "* Since BERT takes alot of resources, use a small batch size (4-8)\n",
    "* Computing the BERT representation, make sure you pass the mask\n",
    "\n",
    "**[10 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "     |████████████████████████████████| 4.4 MB 3.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.23.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 16.0 MB/s            \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "     |████████████████████████████████| 682 kB 59.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3.10/site-packages (from transformers) (2.27.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "     |████████████████████████████████| 101 kB 2.3 MB/s            \n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "     |████████████████████████████████| 763 kB 55.4 MB/s            \n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 1.7 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3.10/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.10/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/lib/python3.10/site-packages (from requests->transformers) (2.0.11)\n",
      "Installing collected packages: tqdm, pyyaml, filelock, tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.8.1 pyyaml-6.0 regex-2022.6.2 tokenizers-0.12.1 tqdm-4.64.0 transformers-4.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huggingface documentation used:\n",
    "+ https://huggingface.co/docs/transformers/preprocessing  \n",
    "+ https://huggingface.co/docs/transformers/training  \n",
    "\n",
    "#### Tutorials used:  \n",
    "+ The dataset, dataloader, and the implementation (including certain decisions made there) were heavily inspired by the following video:  https://youtu.be/vNKIg8rXK6w?t=678, from the timestamped section to around 35:40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start with making a list of possible classes (word senses), so that it is\n",
    "# the same no matter if some of the classes are missing from, say, the test set.\n",
    "# We tried doing this with a set of classes, but this yielded inconsistent results when re-running the notebook with the same\n",
    "# data splits, so despite iterating through a list being more time consuming, we settled on this one.\n",
    "data = pd.read_csv('wsd_test.csv', header=None)\n",
    "data2 = pd.read_csv('wsd_train.csv', header=None)\n",
    "        \n",
    "classes = []\n",
    "for i in range(0,len(data)):\n",
    "    item = data.iloc[i]\n",
    "    word_sense = str(item[0])\n",
    "    if word_sense not in classes:\n",
    "        classes.append(word_sense)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "for i in range(0,len(data2)):\n",
    "    item = data2.iloc[i]\n",
    "    word_sense = str(item[0])\n",
    "    if word_sense not in classes:\n",
    "        classes.append(word_sense)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead%2:41:12::', 'time%1:11:00::', 'line%1:09:00::', 'find%2:40:02::', 'position%1:26:00::', 'see%2:39:02::', 'line%1:04:01::', 'critical%5:00:00:indispensable:00', 'serve%2:41:00::', 'common%5:00:00:shared:00', 'extend%2:30:02::', 'keep%2:42:00::', 'extend%2:30:01::', 'life%1:28:01::', 'serve%2:41:02::', 'professional%5:00:00:white-collar:00', 'national%3:00:00::', 'build%2:36:00::', 'national%5:00:00:public:00', 'professional%3:00:02::', 'see%2:31:00::', 'hold%2:31:10::', 'case%1:11:00::', 'build%2:30:02::', 'line%1:15:02::', 'security%1:14:00::', 'serve%2:42:03::', 'time%1:28:05::', 'active%3:00:07::', 'positive%5:00:00:plus:00', 'force%1:04:01::', 'keep%2:41:03::', 'point%1:10:01::', 'build%2:36:09::', 'place%1:15:04::', 'bring%2:36:01::', 'find%2:31:10::', 'force%1:14:02::', 'serve%2:33:00::', 'physical%5:00:02:material:01', 'national%3:01:01::', 'active%3:00:03::', 'build%2:31:03::', 'place%1:04:01::', 'see%2:39:00::', 'lead%2:38:01::', 'follow%2:41:00::', 'position%1:04:01::', 'find%2:32:01::', 'serve%2:42:01::', 'hold%2:36:00::', 'bring%2:35:00::', 'order%1:10:01::', 'active%5:00:00:involved:00', 'major%3:00:07::', 'find%2:32:00::', 'see%2:39:12::', 'physical%3:00:00::', 'lead%2:42:03::', 'case%1:10:01::', 'time%1:28:00::', 'hold%2:42:00::', 'common%3:00:01::', 'order%1:26:00::', 'security%1:04:00::', 'find%2:40:00::', 'life%1:26:01::', 'build%2:30:10::', 'extend%2:40:05::', 'life%1:03:00::', 'force%1:14:00::', 'position%1:09:00::', 'physical%3:01:00::', 'physical%5:00:00:material:01', 'case%1:04:00::', 'professional%3:01:00::', 'critical%3:00:03::', 'build%2:30:00::', 'active%5:00:00:operational:00', 'common%5:00:00:familiar:02', 'keep%2:40:00::', 'order%1:10:03::', 'point%1:15:00::', 'critical%3:00:01::', 'order%1:10:00::', 'major%3:00:01::', 'bad%5:00:00:intense:00', 'follow%2:38:00::', 'bring%2:35:04::', 'positive%5:00:00:advantageous:00', 'security%1:12:00::', 'major%3:00:06::', 'regular%5:00:00:symmetrical:00', 'place%1:26:00::', 'place%1:15:06::', 'line%1:06:07::', 'regular%5:00:00:scheduled:00', 'hold%2:40:04::', 'line%1:06:09::', 'see%2:31:01::', 'force%1:14:01::', 'extend%2:30:09::', 'life%1:28:02::', 'point%1:26:00::', 'hold%2:31:01::', 'positive%3:00:01::', 'hold%2:40:00::', 'bad%5:00:00:inferior:02', 'order%1:14:00::', 'serve%2:42:00::', 'keep%2:42:07::', 'positive%3:00:04::', 'professional%3:01:01::', 'life%1:28:00::', 'security%1:21:04::', 'lead%2:41:00::', 'time%1:03:00::', 'point%1:09:02::', 'regular%5:00:00:frequent:00', 'common%3:00:02::', 'security%1:26:00::', 'bring%2:38:00::', 'position%1:15:00::', 'position%1:07:01::', 'force%1:07:02::', 'see%2:31:03::', 'lead%2:42:12::', 'force%1:18:00::', 'place%1:15:00::', 'lead%2:38:00::', 'follow%2:38:01::', 'life%1:18:00::', 'keep%2:40:09::', 'point%1:28:00::', 'position%1:26:02::', 'extend%2:40:04::', 'bad%3:00:00::', 'national%5:00:00:domestic:00', 'follow%2:40:00::', 'positive%5:00:00:formal:01', 'follow%2:38:13::', 'hold%2:35:03::', 'national%3:00:01::', 'time%1:28:06::', 'point%1:09:01::', 'keep%2:40:13::', 'find%2:39:02::', 'critical%5:00:00:crucial:00', 'place%1:10:02::', 'force%1:07:01::', 'lead%2:42:01::', 'regular%5:00:00:standard:02', 'security%1:21:01::', 'hold%2:35:00::', 'follow%2:42:02::', 'case%1:10:02::', 'case%1:26:00::', 'keep%2:32:00::', 'case%1:09:00::', 'regular%3:00:00::', 'see%2:32:00::', 'serve%2:41:13::', 'bad%5:00:00:invalid:00', 'physical%5:00:00:natural:03', 'critical%3:00:02::', 'find%2:39:01::', 'follow%2:41:02::', 'serve%2:42:12::', 'major%3:00:02::', 'extend%2:30:06::', 'professional%3:00:01::', 'line%1:06:03::', 'find%2:36:00::', 'hold%2:32:11::', 'physical%5:00:00:forceful:00', 'follow%2:42:05::', 'build%2:36:04::', 'security%1:10:00::', 'follow%2:36:00::', 'line%1:14:02::', 'national%3:01:00::', 'build%2:36:10::', 'bring%2:36:00::', 'see%2:41:11::', 'point%1:23:01::', 'serve%2:35:00::', 'life%1:09:00::', 'regular%5:00:00:normal:01', 'see%2:31:02::', 'hold%2:40:02::', 'case%1:06:00::', 'keep%2:40:01::', 'hold%2:41:15::', 'regular%5:00:00:usual:00', 'line%1:04:00::', 'see%2:39:03::', 'follow%2:42:00::', 'bring%2:30:00::', 'build%2:30:05::', 'line%1:10:02::', 'extend%2:29:01::', 'see%2:36:00::', 'build%2:41:00::', 'life%1:07:01::', 'regular%5:00:00:steady:00', 'place%1:04:00::', 'case%1:18:03::', 'life%1:26:02::', 'keep%2:41:01::', 'keep%2:31:00::', 'active%3:00:01::', 'force%1:07:00::', 'find%2:31:09::', 'line%1:06:01::', 'find%2:40:01::', 'keep%2:35:10::', 'lead%2:42:04::', 'bring%2:40:02::', 'bring%2:37:05::', 'line%1:14:01::', 'point%1:09:00::', 'follow%2:41:10::']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Dataset(Dataset):\n",
    "    def __init__(self, data_path, attributes, max_token_len=128):\n",
    "        self.data_path = data_path\n",
    "        self.attributes = list(attributes)\n",
    "        self.max_token_len = max_token_len\n",
    "        self.prepare_data()\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        data = pd.read_csv(self.data_path, header=None)\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.data))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        word_sense = str(item[0])\n",
    "        ### the following are unnecessary\n",
    "        #lemma = str(item[1]) \n",
    "        #position = int(item[2])\n",
    "        context = str(item[3])\n",
    "        attributes = torch.FloatTensor([1 if x == word_sense else 0 for x in self.attributes])\n",
    "        \n",
    "        # encoding is not done here anymore since it was requested that it be\n",
    "        # done batch by batch (and padded to batch length)\n",
    "        \n",
    "        return {\n",
    "            'context': context,\n",
    "            'labels': attributes.to(device)\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertCollate():\n",
    "    # custom collate class based on the one used in LSTMs where encoding happens\n",
    "    def __init__(self, tokenizer, max_token_len=256):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        contexts = []\n",
    "        labels = []\n",
    "        \n",
    "        for element in batch:\n",
    "            contexts.append(element['context'])          \n",
    "            labels.append(element['labels'])\n",
    "\n",
    "        tokens = self.tokenizer(contexts, \n",
    "                                            add_special_tokens=True, \n",
    "                                            return_tensors='pt',\n",
    "                                            truncation=True, \n",
    "                                            max_length=self.max_token_len, \n",
    "                                            padding=True, # changed from max len\n",
    "                                            return_attention_mask=True,\n",
    "                                           is_split_into_words=False)\n",
    "        \n",
    "        # all of the output is moved to device, labels are stacked since\n",
    "        # it has to be a tensor, not a list\n",
    "        input_ids=tokens['input_ids'].to(device)\n",
    "        attention_masks=tokens['attention_mask'].to(device)\n",
    "        labels = torch.stack(labels).to(device)\n",
    "        \n",
    "        return input_ids, attention_masks, labels\n",
    "\n",
    "\n",
    "def bert_dataloader(dataset, tokenizer, batch_size=4, shuffle=True): \n",
    "    # setting up a dataloader with the BertCollate, similar to what we did\n",
    "    # in the LSTM\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=BertCollate(tokenizer) )\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "learning_rate = 0.000001\n",
    "batch_size = 4\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_WSD(nn.Module):\n",
    "    def __init__(self, model_name, classes):\n",
    "        super().__init__()\n",
    "        # your code goes here\n",
    "        self.bert = BertModel.from_pretrained(model_name, return_dict=True)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, len(classes))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        input_ids = batch[0]\n",
    "        attention_mask = batch[1]\n",
    "        labels = batch[2] \n",
    "        #bert\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #getting a sentence representation\n",
    "        pooled_output = torch.mean(output.last_hidden_state, 1)  # so we get 1 representation for every sentence\n",
    "        #classification\n",
    "        predictions = self.classifier(pooled_output)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 : Average Loss = 0.68737\n",
      "Batch 1000 : Average Loss = 0.42045\n",
      "Batch 2000 : Average Loss = 0.34449\n",
      "Batch 3000 : Average Loss = 0.29444\n",
      "Batch 4000 : Average Loss = 0.2565\n",
      "Batch 5000 : Average Loss = 0.22659\n",
      "Batch 6000 : Average Loss = 0.20255\n",
      "Batch 7000 : Average Loss = 0.18294\n",
      "Batch 8000 : Average Loss = 0.16676\n",
      "Batch 9000 : Average Loss = 0.15327\n",
      "Batch 10000 : Average Loss = 0.1419\n",
      "Batch 11000 : Average Loss = 0.13223\n",
      "Batch 12000 : Average Loss = 0.12395\n",
      "Batch 13000 : Average Loss = 0.1168\n",
      "Batch 14000 : Average Loss = 0.11058\n",
      "Batch 15000 : Average Loss = 0.10512\n",
      "Epoch 0 : Average Loss = 0.10406\n",
      "Batch 0 : Average Loss = 0.02651\n",
      "Batch 1000 : Average Loss = 0.02787\n",
      "Batch 2000 : Average Loss = 0.0275\n",
      "Batch 3000 : Average Loss = 0.02721\n",
      "Batch 4000 : Average Loss = 0.02694\n",
      "Batch 5000 : Average Loss = 0.02671\n",
      "Batch 6000 : Average Loss = 0.02649\n",
      "Batch 7000 : Average Loss = 0.02632\n",
      "Batch 8000 : Average Loss = 0.02618\n",
      "Batch 9000 : Average Loss = 0.02602\n",
      "Batch 10000 : Average Loss = 0.02588\n",
      "Batch 11000 : Average Loss = 0.02573\n",
      "Batch 12000 : Average Loss = 0.02559\n",
      "Batch 13000 : Average Loss = 0.02546\n",
      "Batch 14000 : Average Loss = 0.02532\n",
      "Batch 15000 : Average Loss = 0.02518\n",
      "Epoch 1 : Average Loss = 0.02515\n",
      "Batch 0 : Average Loss = 0.02644\n",
      "Batch 1000 : Average Loss = 0.02248\n",
      "Batch 2000 : Average Loss = 0.02235\n",
      "Batch 3000 : Average Loss = 0.02214\n",
      "Batch 4000 : Average Loss = 0.02202\n",
      "Batch 5000 : Average Loss = 0.02186\n",
      "Batch 6000 : Average Loss = 0.02171\n",
      "Batch 7000 : Average Loss = 0.02152\n",
      "Batch 8000 : Average Loss = 0.02134\n",
      "Batch 9000 : Average Loss = 0.02114\n",
      "Batch 10000 : Average Loss = 0.02093\n",
      "Batch 11000 : Average Loss = 0.02074\n",
      "Batch 12000 : Average Loss = 0.02055\n",
      "Batch 13000 : Average Loss = 0.02035\n",
      "Batch 14000 : Average Loss = 0.02017\n",
      "Batch 15000 : Average Loss = 0.01999\n",
      "Epoch 2 : Average Loss = 0.01995\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: the model that we fine-tuned is saved as trained_BERT.model, see below. Do not re-run this\n",
    "# code if you need to access anything from the model. Instead, move below to where it is loaded before\n",
    "# evaluation and run it from there.\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "model = BERT_WSD(model_name, classes)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "dataset = BERT_Dataset('wsd_train.csv', classes, max_token_len=256)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    # we generate a new loader for every epoch\n",
    "    loader = bert_dataloader(dataset, tokenizer, batch_size=4, shuffle=True)\n",
    "    total_loss = 0\n",
    "    for i, batch in enumerate(loader):\n",
    "        labels = batch[2] \n",
    "        output = model(batch)\n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        total_loss += loss.item()\n",
    "        print_every=1000\n",
    "        if i%print_every==0:\n",
    "            print(f'Batch {i} : Average Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "        \n",
    "        # calculate gradients\n",
    "        loss.backward()\n",
    "        # update model weights\n",
    "        optimizer.step()\n",
    "        # reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f'Epoch {epoch} : Average Loss = {round(total_loss/(i+1),5)}')#, end='\\r')\n",
    "    \n",
    "# test model after all epochs are completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 2 : Average Loss = 0.01995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the fine-tuned model for later reusing; please avoid fully re-running the code above\n",
    "torch.save(model, 'trained_BERT.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_loaded = torch.load('trained_BERT.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_wordsense(labels, classes):\n",
    "    for i in range(0, len(classes)):\n",
    "        if labels[i] == 1:\n",
    "            return classes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At batch 0 : Average Accuracy = 0.0\n",
      "At batch 1000 : Average Accuracy = 0.5084915084915085\n",
      "At batch 2000 : Average Accuracy = 0.5152423788105946\n",
      "At batch 3000 : Average Accuracy = 0.5231589470176607\n",
      "At batch 4000 : Average Accuracy = 0.5276180954761309\n",
      "At batch 5000 : Average Accuracy = 0.523495300939812\n",
      "At batch 6000 : Average Accuracy = 0.5199133477753708\n",
      "At batch 7000 : Average Accuracy = 0.5186401942579631\n",
      "At batch 8000 : Average Accuracy = 0.5178102737157855\n",
      "At batch 9000 : Average Accuracy = 0.5186090434396178\n",
      "At batch 10000 : Average Accuracy = 0.5228477152284772\n",
      "At batch 11000 : Average Accuracy = 0.5232251613489682\n",
      "At batch 12000 : Average Accuracy = 0.5246229480876594\n",
      "At batch 13000 : Average Accuracy = 0.5218060149219291\n",
      "At batch 14000 : Average Accuracy = 0.5223912577673023\n",
      "At batch 15000 : Average Accuracy = 0.5234984334377708\n",
      "Test set accuracy = 0.5233085672956802\n",
      "Per word form accuracy:\n",
      "\tThe accuracy for the word form \"lead\" = 0.25547445255474455\n",
      "\tThe accuracy for the word form \"time\" = 0.33111111111111113\n",
      "\tThe accuracy for the word form \"line\" = 0.8356417359187442\n",
      "\tThe accuracy for the word form \"find\" = 0.6570247933884298\n",
      "\tThe accuracy for the word form \"position\" = 0.6266375545851528\n",
      "\tThe accuracy for the word form \"see\" = 0.7688292319164802\n",
      "\tThe accuracy for the word form \"critical\" = 0.3870967741935484\n",
      "\tThe accuracy for the word form \"serve\" = 0.37083993660855785\n",
      "\tThe accuracy for the word form \"common\" = 0.41420118343195267\n",
      "\tThe accuracy for the word form \"extend\" = 0.4758909853249476\n",
      "\tThe accuracy for the word form \"keep\" = 0.7157695939565628\n",
      "\tThe accuracy for the word form \"life\" = 0.47804878048780486\n",
      "\tThe accuracy for the word form \"professional\" = 0.49884526558891457\n",
      "\tThe accuracy for the word form \"national\" = 0.16173120728929385\n",
      "\tThe accuracy for the word form \"build\" = 0.35181236673773986\n",
      "\tThe accuracy for the word form \"hold\" = 0.5208681135225376\n",
      "\tThe accuracy for the word form \"case\" = 0.4133611691022965\n",
      "\tThe accuracy for the word form \"security\" = 0.4589041095890411\n",
      "\tThe accuracy for the word form \"active\" = 0.39855072463768115\n",
      "\tThe accuracy for the word form \"positive\" = 0.20717131474103587\n",
      "\tThe accuracy for the word form \"force\" = 0.601123595505618\n",
      "\tThe accuracy for the word form \"point\" = 0.56951871657754\n",
      "\tThe accuracy for the word form \"place\" = 0.5717821782178217\n",
      "\tThe accuracy for the word form \"bring\" = 0.3359223300970874\n",
      "\tThe accuracy for the word form \"physical\" = 0.6074270557029178\n",
      "\tThe accuracy for the word form \"follow\" = 0.36321483771251933\n",
      "\tThe accuracy for the word form \"order\" = 0.6702412868632708\n",
      "\tThe accuracy for the word form \"major\" = 0.3821656050955414\n",
      "\tThe accuracy for the word form \"bad\" = 0.5285714285714286\n",
      "\tThe accuracy for the word form \"regular\" = 0.4942528735632184\n"
     ]
    }
   ],
   "source": [
    "bert_loaded.eval()\n",
    "test_dataset = BERT_Dataset('wsd_test.csv', classes, max_token_len=128)\n",
    "test_loader = bert_dataloader(test_dataset, tokenizer, batch_size=1, shuffle=True)\n",
    "total_acc = 0\n",
    "total_samples = 0\n",
    "per_wf_acc = {}\n",
    "\n",
    "for ws in classes:\n",
    "    wf = get_wf(ws)\n",
    "    if wf not in per_wf_acc:\n",
    "        per_wf_acc[wf] = {'sum': 0, 'count': 0}\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    labels = batch[2][0]\n",
    "    ws = find_wordsense(labels, classes)\n",
    "    wf = get_wf(ws)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = bert_loaded(batch)[0]\n",
    "\n",
    "    # one-hot encoding predictions in order to compare them with the labels for\n",
    "    # accuracy calculations; this could be done also by comparing if the indices\n",
    "    # for the torch.max(whatever) are the same, but this was the first solution\n",
    "    # we came up with\n",
    "    top_pred = torch.max(predictions)\n",
    "    one_hot_preds = []\n",
    "    for prediction in predictions:\n",
    "        if prediction == top_pred:\n",
    "            one_hot_preds.append(1)\n",
    "        else:\n",
    "            one_hot_preds.append(0)\n",
    "            \n",
    "    # doing accuracy        \n",
    "    if one_hot_preds == list(labels):\n",
    "        total_acc += 1\n",
    "        total_samples += 1\n",
    "        per_wf_acc[wf]['sum'] += 1\n",
    "        per_wf_acc[wf]['count'] +=1\n",
    "    else:\n",
    "        total_acc += 0\n",
    "        total_samples += 1\n",
    "        per_wf_acc[wf]['sum'] += 0\n",
    "        per_wf_acc[wf]['count'] +=1\n",
    "    \n",
    "    \n",
    "    print_every=1000\n",
    "    if i%print_every==0:\n",
    "        print(f'At batch {i} : Average Accuracy = {total_acc/total_samples}')#, end='\\r')\n",
    "\n",
    "# calculating per word form accuracy\n",
    "per_wf_acc_calc = {}\n",
    "for k,v in per_wf_acc.items():\n",
    "    summed = v['sum']\n",
    "    count = v['count']\n",
    "    accuracy = summed / count\n",
    "    per_wf_acc_calc[k] = accuracy\n",
    "        \n",
    "full_accuracy = total_acc / total_samples\n",
    "    \n",
    "\n",
    "print(f'Test set accuracy = {full_accuracy}')\n",
    "print('Per word form accuracy:')\n",
    "for k,v in per_wf_acc_calc.items():\n",
    "    print(f'\\tThe accuracy for the word form \"{k}\" = {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>number_of_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.382</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.414</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.529</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.331</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.387</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.499</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.627</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.607</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.162</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.476</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.572</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.459</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.601</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.570</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.255</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.494</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.413</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.478</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.371</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.657</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.352</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.521</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.716</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.769</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.363</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.836</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  number_of_senses\n",
       "major            0.382                 4\n",
       "common           0.414                 4\n",
       "bad              0.529                 4\n",
       "active           0.399                 5\n",
       "time             0.331                 5\n",
       "order            0.670                 5\n",
       "critical         0.387                 5\n",
       "positive         0.207                 5\n",
       "professional     0.499                 5\n",
       "position         0.627                 6\n",
       "physical         0.607                 6\n",
       "national         0.162                 6\n",
       "extend           0.476                 7\n",
       "place            0.572                 7\n",
       "security         0.459                 7\n",
       "force            0.601                 8\n",
       "bring            0.336                 8\n",
       "point            0.570                 8\n",
       "lead             0.255                 8\n",
       "regular          0.494                 8\n",
       "case             0.413                 8\n",
       "life             0.478                 9\n",
       "serve            0.371                 9\n",
       "find             0.657                10\n",
       "build            0.352                10\n",
       "hold             0.521                11\n",
       "keep             0.716                11\n",
       "see              0.769                11\n",
       "follow           0.363                11\n",
       "line             0.836                11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to what we did in the LSTM model\n",
    "bert_wf_acc = pd.Series(per_wf_acc_calc).apply(lambda x: round(x,3))\n",
    "bert_wf_acc.name = 'accuracy'\n",
    "bert_wf_acc = bert_wf_acc.to_frame()\n",
    "data['words'] = data[0].apply(lambda x: x.split('%')[0]) # I could just use word-form from the start. Yeye i forgot this column\n",
    "bert_wf_acc['number_of_senses'] = data.groupby('words')[0].nunique()\n",
    "\n",
    "bert_wf_acc = bert_wf_acc.sort_values(by='number_of_senses')\n",
    "bert_wf_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the difference between the first and second approach. What kind of representations are the different approaches using to predict word-senses? **[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were not sure if what is meant here is the first and second LSTM approaches, or LSTMs vs. BERT, so we wrote about them all.  \n",
    "+ LSTM - predicting for the word index. In this approach we look at both sides of the context, and we predict something for the word at the given index; it's like predicting the best fitting word if word senses were separate words. We feel like this is a bit like BOW modelling, but we have bidirectional context. Essentially, we use context from both sides to predict something for a given position within the sentence.\n",
    "+ LSTM - final hidden state. Here we have representations of the whole sentence, from both directions, that we use to try to predict the right word sense. It's a bit more like a classification task rather than just predicting a word. While both approaches essentially do the same, they take slightly different things into account with different weight, so to say.  \n",
    "\n",
    "Extra:  \n",
    "\n",
    "+ BERT - sentence representation (pooled word representations). Similar to the final hidden state LSTM model, we have a representation of the sentence based on the words in the sentence, and we try to predict a \"class\" based on that. The sentence representation is constructed using a mean of representations for all the elements of the sentence. This is the recommended way of doing it for multilabel classification, though we could also have used the built-in sentence representation (the \"start\" token). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model with per-word-form *accuracy* and comment on the results you get, how does the model perform in comparison to the baseline, and how do the models compare to each other? \n",
    "\n",
    "Expand on the evaluation by sorting the word-forms by the number of senses they have. Are word-forms with fewer senses easier to predict? Give a short explanation of the results you get based on the number of senses per word.\n",
    "\n",
    "**[6 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT and LSTM \n",
    "As seen in results below, the trend is not 100% consistent, but it seems like the more senses a given word has, the better the model is at predicting them correctly, which I found to be surprising. It is the words with 10 or 11 forms that have the highest performance (70-80%), although this is by no means fully consistent across the board. We would have expected the words with fewer senses to be better recognized, as there are fewer senses to choose from, ergo, even when randomly selected, there is a higher chance of being correct. However, we always predict from all 222 classes, so that probably influences it. In addition, the words with more senses may be better featured in the data on which the model is fine-tuned, so it is just better at recognizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>number_of_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.671</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.225</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.293</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.341</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.199</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.323</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.332</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.280</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.303</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.269</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.075</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.268</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.372</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.289</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.349</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.332</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.232</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.259</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.295</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.232</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.591</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.227</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.220</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.207</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.403</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.587</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.222</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.246</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.609</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.861</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  number_of_senses\n",
       "bad              0.671                 4\n",
       "common           0.225                 4\n",
       "major            0.293                 4\n",
       "active           0.341                 5\n",
       "professional     0.199                 5\n",
       "positive         0.323                 5\n",
       "order            0.332                 5\n",
       "time             0.280                 5\n",
       "critical         0.303                 5\n",
       "position         0.269                 6\n",
       "national         0.075                 6\n",
       "physical         0.268                 6\n",
       "security         0.372                 7\n",
       "extend           0.289                 7\n",
       "place            0.349                 7\n",
       "case             0.332                 8\n",
       "force            0.232                 8\n",
       "regular          0.259                 8\n",
       "bring            0.295                 8\n",
       "lead             0.232                 8\n",
       "point            0.591                 8\n",
       "life             0.227                 9\n",
       "serve            0.220                 9\n",
       "build            0.207                10\n",
       "find             0.403                10\n",
       "keep             0.587                11\n",
       "hold             0.222                11\n",
       "follow           0.246                11\n",
       "see              0.609                11\n",
       "line             0.861                11"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM approach 1\n",
    "df_wf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>number_of_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.674</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.385</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.328</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.594</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.442</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.515</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.302</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.390</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.426</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.262</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.515</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.458</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.500</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.463</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.417</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.548</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.556</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.276</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.510</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.425</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.477</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.254</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.405</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.659</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.392</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.648</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.879</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  number_of_senses\n",
       "bad              0.674                 4\n",
       "common           0.385                 4\n",
       "major            0.328                 4\n",
       "active           0.547                 5\n",
       "professional     0.594                 5\n",
       "positive         0.442                 5\n",
       "order            0.515                 5\n",
       "time             0.302                 5\n",
       "critical         0.390                 5\n",
       "position         0.426                 6\n",
       "national         0.262                 6\n",
       "physical         0.515                 6\n",
       "place            0.458                 7\n",
       "security         0.500                 7\n",
       "extend           0.463                 7\n",
       "regular          0.417                 8\n",
       "bring            0.336                 8\n",
       "point            0.548                 8\n",
       "force            0.556                 8\n",
       "lead             0.276                 8\n",
       "case             0.311                 8\n",
       "life             0.510                 9\n",
       "serve            0.425                 9\n",
       "find             0.477                10\n",
       "build            0.254                10\n",
       "follow           0.405                11\n",
       "keep             0.659                11\n",
       "hold             0.392                11\n",
       "see              0.648                11\n",
       "line             0.879                11"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM approach 2\n",
    "df_wf_acc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>number_of_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.382</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.414</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.529</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.331</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.387</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.499</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.627</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.607</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.162</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.476</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.572</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.459</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.601</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.570</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.255</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.494</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.413</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.478</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.371</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.657</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.352</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.521</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.716</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.769</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.363</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.836</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  number_of_senses\n",
       "major            0.382                 4\n",
       "common           0.414                 4\n",
       "bad              0.529                 4\n",
       "active           0.399                 5\n",
       "time             0.331                 5\n",
       "order            0.670                 5\n",
       "critical         0.387                 5\n",
       "positive         0.207                 5\n",
       "professional     0.499                 5\n",
       "position         0.627                 6\n",
       "physical         0.607                 6\n",
       "national         0.162                 6\n",
       "extend           0.476                 7\n",
       "place            0.572                 7\n",
       "security         0.459                 7\n",
       "force            0.601                 8\n",
       "bring            0.336                 8\n",
       "point            0.570                 8\n",
       "lead             0.255                 8\n",
       "regular          0.494                 8\n",
       "case             0.413                 8\n",
       "life             0.478                 9\n",
       "serve            0.371                 9\n",
       "find             0.657                10\n",
       "build            0.352                10\n",
       "hold             0.521                11\n",
       "keep             0.716                11\n",
       "see              0.769                11\n",
       "follow           0.363                11\n",
       "line             0.836                11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT\n",
    "bert_wf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'BERT, Accuracy = 52,33%'}, xlabel='number_of_senses', ylabel='accuracy'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, (ax1) = plt.subplots(1,1, figsize=(14,6)) \n",
    "\n",
    "ax1.set_title('BERT, Accuracy = 52,33%')\n",
    "sns.regplot(x=\"number_of_senses\", y=\"accuracy\", data=bert_wf_acc, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'LSTM - Approach 2, Accuracy = 49,50%'}, xlabel='number_of_senses', ylabel='accuracy'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(14,6)) \n",
    "\n",
    "ax1.set_title('LSTM - Approach 1, Accuracy = 37,92%')\n",
    "ax2.set_title('LSTM - Approach 2, Accuracy = 49,50%')\n",
    "sns.regplot(x=\"number_of_senses\", y=\"accuracy\", data=df_wf_acc, ax=ax1)\n",
    "sns.regplot(x=\"number_of_senses\", y=\"accuracy\", data=df_wf_acc2, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the accuracy actually increased with the number of word-senses. This is a bit surpising but impressive as it means the model is not confused by different but similar senses.\n",
    "\n",
    "#### COMPARISON\n",
    "The plots really help compare the three models, but it is also important to look at the overall accuracy.\n",
    "\n",
    "+ In this run, BERT's overall accuracy was 52,33%, LSTM 1 - 37,92%, and LSTM 2 - 49,50%. In this particular comparison, BERT seems to be the best, closely followed by the second approach to LSTM, but it is important to remember that these are still really dependent on luck during training (i.e. they architecture is not infallibly great), as in some other runs BERT underperformed significantly. Fiddling around with parameters allowed for improvement.\n",
    "+ On all of the plots we can see that the line drawn through the results is angled slightly upwards, indicating that in all the models the more senses there are for a word form, the better the model is at predicting them.\n",
    "+ However, just visually, it seems that for LSTM 2 the points are very spread out, with some with very high accuracy and some with very low. BERT ones are the least spread out (the closest to the line). \n",
    "+ It seems like it is the same word forms that perform similarly in different models: \"line\" has a very high accuracy in all of them, and \"national\" - very low. Perhaps all of the senses in the former one are very distinct, while it is not the case in the latter. \n",
    "+ Compared to the baseline, all the models are better, but naturally there is still room for improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the LSTMs perform in comparison to BERT? What's the difference between representations obtained by the LSTMs and BERT? **[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs in this assignment perform worse than BERT. However Approach 2 performed very similarily, which surprised us.\n",
    "The major difference between the two is that for LSTMs we do word embeddings from scratch. This means that we only have a few epochs and limited data to capture the \"meaning\" of the words in the model. In comparison, BERT already has embeddings for a lot of words, and all we need to do is fine tune, or tweak them to fit our task at hand. This means that essentially the meanings of the words are already there, we just need to train the model to classify word senses based on the context.  \n",
    "In terms of purely what we use to get predictions (as explained in the answer to an earlier question), in LSTMs we either get a class prediction for a given index, or we base it on the concatenation of the final hidden states for the left-directional and right-directional LSTM. For BERT we get fine-tuned attention-based output for every element of the sentence, which is then pooled and pushed to a classifier layer, which has been trained to use that input to predict one of the 222 classes/word senses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could we do to improve our LSTM word sense disambiguation models and our BERT model? **[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs:\n",
    "+ We could experiment more with hyperparameters. When developing working structures of the models, we had really bad results due to low dimensionality etc. of our working parameters.\n",
    "+ We could combine the two approaches, as suggested in class (use both the index prediction and the final hidden state to predict the word sense).\n",
    "\n",
    "BERT:\n",
    "+ We could test using the initial sentence representation (on the first token) and see if that gives better results than pooling the representations for all the elements. Both are claimed to be rather similar in results, but perhaps it would make a difference.\n",
    "+ Even though we used the suggested hyperparameters perhaps we could also change something there.\n",
    "\n",
    "Both:\n",
    "+ We could definitely implement dropout (which we forget to do while developing the models now). This would help counteract potential overfitting.\n",
    "+ For now the models choose, regardless of the word we are predicting the sense of, a class/sense out of 222 available ones. This means that \"keep\" can get not only 'keep%2:41:03::' but also 'force%1:18:00::' predicted. Perhaps it would work better if the classifier could only pick from the word senses applicable for the given word. For now just choosing blindly gives us a 1 in 222 chance of being correct. If we narrow it down, we get a, say, 1 in 4 (to 1 in 11) chance, which is a major change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings:\n",
    "\n",
    "[1] Kågebäck, M., & Salomonsson, H. (2016). Word Sense Disambiguation using a Bidirectional LSTM. arXiv preprint arXiv:1606.03568.\n",
    "\n",
    "[2] https://cl.lingfil.uu.se/~nivre/master/NLP-LexSem.pdf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb7b97508d5d951011f17ccbf6001a0d13d65ded8b8713cb82af86b239c935c1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
